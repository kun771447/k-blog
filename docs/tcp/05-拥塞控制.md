# 拥塞控制

- 慢启动

- 拥塞控制

- 快速重传

- 快速恢复

<img src="\tcp\05\2023-02-14-15-13-28-image.png" />

由于 TCP 协议向应用层提供不定长的字节流发送方法，使的 TCP 有意愿去占满整个带宽，当网络中多个 TCP 连接同时试图建立整个带宽时，就可能发生恶心拥塞事件，TCP 拥塞控制算法就降低网络中的拥塞，提升所有 TCP 的连接速度

## 拥塞控制历史

- 以丢包作为依据
  
  - New Reno: RFC6582.BlC: Linux2.6.8-2.6.18
  
  - CUBIC (RFC8312) : Linux2.6.19

- 以探测带宽作为依据
  
  - BBR: Linux4.9

## 慢启动

- 拥塞窗口cwnd(congestion window)
  
  - 通告窗口(接收窗口) rwnd (receiver`s advertised window)
  
  - 发送窗口 swnd = min(cwnd, rwnd)

- 每收到一个 ACK，cwnd 扩充为收到 ACK 的一倍

<img src="\tcp\05\2023-02-14-15-56-13-image.png" />

## 慢启动的初始窗口

- 慢启动初始窗口IW(Initial Window)的变迁
  
  - 1 SMSS: RFC2001 (1997)
  
  - 2 - 4 SMSS: RFC2414 (1998)
    
    - IW = min(4 * SMSS, max (2 * SMSS, 4380bytes))
  
  - 10 SMSS: RFC6928 (2013)
    
    - IW = min(10 * MSS, max(2 * MSS, 14600))
    
    - gogle 发现大多数网页都在 10 个 MSS

## 拥塞避免

<img src="\tcp\05\2023-02-14-20-04-33-image.png" />

在没有拥塞避免算法时，我们的慢启动时成线性增长，当出现丢包，丢包数量就可能非常大

比如上次 cwnd = 20，而我们超过 28 就开始丢包，下次收到 ack, cwnd = 40, 这样就会丢 12    个

- **拥塞避免定义了慢启动阈值 ssthresh(slow start threshold)**
  
  - 达到 ssthresh 后，以线性方式增加 cwnd
  
  - cwnd += SMSS * SMSS / cwnd

再出现**丢包**的情况就将 **慢启动阈值降低为拥塞窗口的一半，再将拥塞定义为一个比较小的值** 

## 慢启动和拥塞避免

<img src="\tcp\05\2023-02-14-20-29-05-image.png" />

## 快速重传

当出现丢包时我们会重新执行慢启动，传输效率也会大幅度下降，当出现场景不是很严重的时候，我们可以采用快速重传和快速恢复

### 为何会接收到失序数据段？

<img src="\tcp\05\2023-02-14-20-34-38-image.png" />

- 若报文丢失，后续的报文到达我们接收端，将会发送连续的失序ACK段确认丢失的报文段
  
  - 拥塞控制针对丢包情况

- 若网络路径与设备导致数据段失序，将会产生少量的失序ACK段

- 若报文重复，将会产生少量的失序ACK段

## 快速重传（RFC2581）

- 接收方:
  
  - 当接收到一个失序数据段时，立刻发送它所期待的缺口ACK序列号
  
  - 当接收到填充失序缺口的数据段时，立刻发送它所期待的下一个ACK序列号

- 发送方
  
  - 当接收到 4 个相同的失序 ACK段时，不再等待重传定时器的触发，立刻基于快速重传机制重发报文段

<img src="\tcp\05\2023-02-14-20-42-37-image.png" />

### 超时不会启动快速重传

<img src="\tcp\05\2023-02-14-20-46-26-image.png" />

如上图 ack9  没有重复发送 达到 4 次，所以不启动

### 快速重传下一定要进入慢启动吗？

- 收到重复的 ack，意味着网络仍在流动
  
  - 慢启动会突然减少数据流

## 快速恢复 (RFC2581)

- **启动快速重传且正常未失序ACK段到达前(比如上图 pkt9)，启动快速恢复**
  
  - 将 ssthresh 设置为当前拥塞窗口 cwnd 的一半，设当前 cwnd 为 ssthresh 加上 3 * MSS
  
  - 每收到一个重复 ACK , cwnd 增加 1 个 MSS
  
  - 当新数据 ACK 到达后，设置 cwnd 为 ssthresh

<img src="\tcp\05\2023-02-14-20-53-39-image.png" />

## SACK与选择性重传算法

### 进重传丢失端，保守乐观

- 累积确认 Sequence 序号的问题
  
  - Client 无法告知收到了 Part4
  
  - Server 发送窗口/Client 接收窗口停止

<img src="\tcp\05\2023-02-19-14-50-18-image.png" />

### 重传丢失段及后发送的所有段

- 重传所有段: 积极悲观
  
  - 可能浪费带宽

- 仅重传丢失段: 保守乐观
  
  - 大量丢包时效率低下

<img src="\tcp\05\2023-02-19-15-09-18-image.png" />

### SACK: TCP Selective Acknowledgment

- RFC 2018

<img src="\tcp\05\2023-02-19-15-10-39-image.png" />

- 选择性确认

<img src="\tcp\05\2023-02-19-15-11-13-image.png" />

- Left Edge of Block

- Right Edge of Block

<img src="\tcp\05\2023-02-19-15-45-13-image.png" />

## 从丢包到测量驱动的拥塞控制算法

### 飞行中的数据和确认报文

<img src="\tcp\05\2023-02-19-15-54-45-image.png" />

瓶颈路由器，在瓶颈路由器过载，等待队列全满 就会出现丢包

### 大管道向小管道传输数据引发拥堵

<img src="\tcp\05\2023-02-19-15-50-43-image.png" />

在瓶颈路由器开始丢包

<img src="\tcp\05\2023-02-19-16-02-30-image.png" />

y: 发送速率

x: 时间

<img src="\tcp\05\2023-02-19-16-05-11-image.png" />

在引入 CUBIC 拥塞控制算法后，他虽然更加平滑，但他也会带来我们 RTT 时延非常大

### 最佳控制点在那？（1979 Leonard Kleinrock）

- 基于丢包的拥塞控制点
  
  - 高时延，大量丢包
  
  - 随着内存便宜，缓冲队列越大，时延更高

- 最佳控制点
  
  - 最大带宽下
  
  - 最小时延
  
  - 最低丢包率

- RTT 与 Bw 独立变化
  
  - 同时只有一个可以被准确测量

<img src="\tcp\05\2023-02-19-16-11-17-image.png" />

   Round Trip TIme： RTT

Data Volume In-Flight:  缓冲队列

Delivery Rate: 带宽

### 空队列效果最好

<img src="\tcp\05\2023-02-19-16-24-50-image.png" />

当我们缓冲队列满了就开始丢包，我们最佳的点就是缓冲队列开始丢包

<img src="\tcp\05\2023-02-19-16-26-26-image.png" />

### BBR: TCP Bottleneck Bandwidth and Round-trip propagation time

- 由Google于2016发布，Linux4.9内核引入，QUIC使用

<img src="\tcp\05\2023-02-19-16-27-38-image.png" />

### Google BBR 拥塞控制算法原理

#### 最佳控制点在那?

- 1979 Leonard Kleinrock

<img src="\tcp\05\2023-02-19-16-31-57-image.png" />

### BBR如何找到准确的RTprop和BtlBw?

<img src="\tcp\05\2023-02-19-16-37-38-image.png" />

nt 是排队时间

RTprop 是从发送到接收数据整个的时间(不包括排队的时间)

### 基于 pacing_gain 调整

- 700 ms 内的测量
  
  - 10-Mbps, 40 ms 链路

- 如果检测带宽变大？
  
  - 定期提升 pacing_gain

<img src="\tcp\05\2023-02-19-16-36-34-image.png" />

### 当线路变换式 pacing_gain 的作用

<img src="\tcp\05\2023-02-19-16-50-14-image.png" />

### 对比 CUBIC 下的慢启动

<img src="\tcp\05\2023-02-19-16-51-05-image.png" />

### 多条初始速度不同的 TCP 链路快速的平均分享带宽

- 100-Mbps/10-ms

<img src="\tcp\05\2023-02-19-16-55-42-image.png" />

### Google B4 WAN 实践

- 2-25倍吞吐量提升

- 累积分布函数

- 75%连接受限于linux kerver 接收缓存

- 在美国-欧洲路径上提升linuxkernal接收缓存上限后有133倍提升

<img src="\tcp\05\2023-02-19-16-57-14-image.png" />

### RTT 大幅度下降

<img src="\tcp\05\2023-02-19-16-58-25-image.png" />

### 不同丢包率下的吞吐量：CUBIC VS BBR

<img src="\tcp\05\2023-02-19-16-58-49-image.png" />

### SGSN 移动网络

<img src="\tcp\05\2023-02-19-17-02-12-image.png" />

三次握手建立连接的重发次数和超时实践都是有限的

### 收到 ACK 时 更新 RTprop、BtlBw

<img src="\tcp\05\2023-02-19-17-03-59-image.png" />

### 当发送数据时根据 pacing_gain 周期性探测带宽有没有发生变化

<img src="\tcp\05\2023-02-19-17-05-30-image.png" />
